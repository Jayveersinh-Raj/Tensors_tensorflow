{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UyGzs1tJWOPy",
        "J8pfbYjRZjDS",
        "Fq9R8Y33knkP"
      ],
      "authorship_tag": "ABX9TyNkvxT7+FsJylKfGykyv0YJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayveersinh-Raj/Tensors_tensorflow/blob/main/0_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fundamental conepts of tensor using tensorflow\n",
        "\n",
        "Index: <br>\n",
        "1) Intro. to tensors <br>\n",
        "2) Getting info. from tensors <br>\n",
        "3) Manipulation of tensors <br>\n",
        "4) Tensors and Numpy <br>\n",
        "5) Using @tf.function to fasten normal python functions<br>\n",
        "6) GPUs and TPUs with tensorflow\n"
      ],
      "metadata": {
        "id": "UyGzs1tJWOPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) Intro. to tensors"
      ],
      "metadata": {
        "id": "J8pfbYjRZjDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow import\n",
        "import tensorflow as tf #tf as alias, but can be aribtary, however tf is the norm\n",
        "\n",
        "#Just checking the version\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaEYLdF9bAm-",
        "outputId": "6e596787-70f4-4497-b313-71ff808d7323"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To create tensor using tf.constant()\n",
        "\n",
        "#There are multiple ways to create tensors however, but further, we see\n",
        "#that tensorflow has some build in modules to auto do it\n",
        "const = tf.constant(7) #A scalar constant\n",
        "const"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PnXnBzPbzy6",
        "outputId": "21cea857-657e-432e-f207-8b008818421f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the number of dimensions using ndim\n",
        "const.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3BL7WOycBnH",
        "outputId": "13983535-56db-42b6-ce63-03ff01611e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating vector\n",
        "vector = tf.constant([10,10])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WenIlrDYdY6d",
        "outputId": "2821f7f8-4c4a-48d8-954d-032eef594d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check vector dimensions\n",
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFmWkZ7Odzoj",
        "outputId": "07dcfb0d-b3ed-4956-8024-98bc0b56f827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a matrix\n",
        "matrix = tf.constant([[5,3],[3,5]])\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEaahJ6Qd68Z",
        "outputId": "3ea11a9f-fadd-4315-c9ee-7752630e544c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[5, 3],\n",
              "       [3, 5]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim #matrix dimensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh8ow5SreVH2",
        "outputId": "81b164f3-b64a-4866-99ff-c96a9ad83e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New matrix\n",
        "new_matrix = tf.constant([[5.,3.],[3.,5.]], dtype = tf.float16) #specify the data type\n",
        "#By default it is int32, float16 is 16 precision, thus less memory\n",
        "#If we get data type error ever, we can manipulate it using this\n",
        "new_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU1CO6lfebwF",
        "outputId": "e701712d-0421-4b12-9f41-fc04fcc840cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float16, numpy=\n",
              "array([[5., 3.],\n",
              "       [3., 5.]], dtype=float16)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimension of the new matrix\n",
        "new_matrix.ndim #these no. of dimensions are number of numbers inside a shape()\n",
        "# 2,2 thus, 2 numbers of 2 dimensions, in short highest no. of index in shape() = no. of dimensions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwDTt-QsfSpo",
        "outputId": "29a2109b-b076-4e91-d3e6-9fce2d9ba929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "tensor = tf.constant([[1,2,3],[1,2,3],[1,2,3]])\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiHWdJbdfvrM",
        "outputId": "d0d920b9-e0bc-4b35-e934-060a9d1cbc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1, 2, 3],\n",
              "       [1, 2, 3],\n",
              "       [1, 2, 3]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of dimensions\n",
        "tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pc0uH2agBNM",
        "outputId": "6cb62ab6-d7df-4c91-eb9d-cad17a56e8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus,<br>\n",
        "1) Scalar: a constant number<br>\n",
        "2) Vector: a number and it's dimension<br>\n",
        "3) Matrix: a 2D array of numbers<br>\n",
        "4) Tensor: an n dimensional array of       numbers<br>\n",
        " * if n is 0 then it is a scalar\n",
        " * if n is 1 then it is a vector\n",
        " * if n is 2 then it is a matrix"
      ],
      "metadata": {
        "id": "9OLvQYYxgNIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New way to create tensors using 'tf.Variable'"
      ],
      "metadata": {
        "id": "ZcHz8leVg51K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change able tensor vs unchanageable tensors\n",
        "changeable = tf.Variable([5,3])\n",
        "unchangeable = tf.constant([5,3])\n",
        "changeable,unchangeable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI7OeqPliEHG",
        "outputId": "2a880079-1704-4b4a-b2c4-90b65a8d28df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([5, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([5, 3], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The method that you could think of, but won't work\n",
        "# changeable[0] = 1\n",
        "# changeable"
      ],
      "metadata": {
        "id": "RLOaxPxXi1aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The correct way to do that use .assign()\n",
        "changeable[0].assign(1)\n",
        "changeable"
      ],
      "metadata": {
        "id": "M6Z30OUUjCVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0525dee-2110-4ace-9eaa-4fbb2a02d8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([1, 3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What happens if unchangable is tried to be manipulated\n",
        "# unchangeable[0].assign(1)\n",
        "# unchangeable"
      ],
      "metadata": {
        "id": "P4nNKczJjTFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”‘**Note**: Rarely in practise you need to decide between tf.Variable and tf.constant, as TensorFlow does it for us. However, if not sure, use tf.constant, and change if needed later"
      ],
      "metadata": {
        "id": "ddLrEnqAj-bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Random Tensors\n",
        "\n",
        "Random tensors are of random size with random numbers"
      ],
      "metadata": {
        "id": "r_oepdZ4k8MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we know changeable and unchangeable\n",
        "# Now, Create 2 Random tensors\n",
        "\n",
        "random_one = tf.random.Generator.from_seed(42) #set seed for reproducibility\n",
        "random_one = random_one.normal(shape=(3,2)) # chooses from a normal distribution\n",
        "#with the shape of (3,2) meaning for an ease 3 rows, each with 2 elements\n",
        "\n",
        "random_2 = tf.random.Generator.from_seed(42)\n",
        "random_2 = random_2.normal(shape=(3,2))\n",
        "\n",
        "#Equality check\n",
        "random_one, random_2, random_one == random_2"
      ],
      "metadata": {
        "id": "1kzdtCPWj1Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663ee72d-7187-4aea-ff67-df6dc6cef8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193763, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
              " array([[ True,  True],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "They are pseudo random because we set a seed, with same seed as 42 in both, they are the same, changing the number in the seed will yield different result"
      ],
      "metadata": {
        "id": "_UyKv9xooYc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shuffle the order of elements in a tensor"
      ],
      "metadata": {
        "id": "Fq9R8Y33knkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For example to learn multiple images at a same, it is useful\n",
        "# Valueable for when you want to shuffle your data so the inherent order doesn't effect learning\n",
        "not_shuffled = tf.constant([[10,3],[3,5],[1,2]])\n",
        "# not_shuffled.ndim\n",
        "\n",
        "# shuffle our not_shuffled\n",
        "tf.random.shuffle(not_shuffled)\n"
      ],
      "metadata": {
        "id": "8Rb2k8yrook4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62735e58-a653-439a-c2ae-0f86f11d6fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  3],\n",
              "       [ 3,  5],\n",
              "       [ 1,  2]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle with seed\n",
        "tf.random.set_seed(42) # Global seed\n",
        "tf.random.shuffle(not_shuffled, seed = 42) # Operational level seed\n",
        "\n",
        "# As seen before seed will produce pseudo random, and ordering change stays same for a particular seed value\n",
        "# If no seed is choosen, it will generate random seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqHqZZzw_Fn7",
        "outputId": "82075309-8ad5-4f6c-8393-d80b7c1a28e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  3],\n",
              "       [ 3,  5],\n",
              "       [ 1,  2]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Other ways to create tensors"
      ],
      "metadata": {
        "id": "8jvAtg5yB0v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Similar to numpy\n",
        "tf.ones([2,3]) # creates the tensor of shape (2,3) with all ones\n",
        "\n",
        "tf.zeros([2,2]) # creates with shape (2,2) all the zeros, also \n",
        "# we can write tf.zeros(shape = (2,2)), it will yield same result\n",
        "# Same with .ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ1N6O9eC9TK",
        "outputId": "40c71314-38be-4920-9a4b-5796d954568c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[0., 0.],\n",
              "       [0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turn NumPy arrays into tensors\n",
        "The main difference between numpy and tensorflow tensors is that tensors can be run on a GPU for faster numerical computing. Otherwise, they are pretty much the same"
      ],
      "metadata": {
        "id": "pzi8Fl2-D0C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting NumPy arrays to tensors\n",
        "import numpy as np \n",
        "A = np.arange(1, 25, dtype = np.int32) # create a NumPy array between 1 and 25\n",
        "A\n",
        "\n",
        "# Norm is X = tf.constant(some_matrix) # capital for a matrix or tensor\n",
        "#         y = tf.constant(vector) # non capital for a vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JayiXck-Dam3",
        "outputId": "86ca55ac-698e-4d2a-d854-43e4319215ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting that array A of numpy into a tensor\n",
        "A = tf.constant(A)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fadD0375FTq8",
        "outputId": "ffa39009-2fd4-4ec6-bbde-4eaa6424158c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Giving shape to our tensor\n",
        "A = tf.constant(A, shape = (2,3,4)) # 2 would be first bracket, 3 would be second, and 4 would be last\n",
        "# since 24 elements 2*3*4 = 24\n",
        "# Keep in mind, whatever shape you give, all of it's product should be equal to total no. of elements\n",
        "# in this case 2*3*4 = total no. of elements (To accomodate all elements)\n",
        "A\n",
        "\n",
        "# Pay attention to brackets to understand better, there are 4 elements in the most inside brackets\n",
        "# 3 vectors/blocks within 2nd brackets\n",
        "# 2 nested vectors/blocks within the 1st bracket\n",
        "# Thus, first dimension is 2, second is 2 and third is 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y5fBziHF1Dh",
        "outputId": "3abe86be-e35c-4e42-c534-f2c8cfd646ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
              "array([[[ 1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12]],\n",
              "\n",
              "       [[13, 14, 15, 16],\n",
              "        [17, 18, 19, 20],\n",
              "        [21, 22, 23, 24]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try the shape of 6*2*2 = 24\n",
        "A = tf.constant(A, shape = (6,2,2))\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9-MNApmHHO2",
        "outputId": "6a0d2e48-a14a-4d2d-b16e-9c104a965200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 2, 2), dtype=int32, numpy=\n",
              "array([[[ 1,  2],\n",
              "        [ 3,  4]],\n",
              "\n",
              "       [[ 5,  6],\n",
              "        [ 7,  8]],\n",
              "\n",
              "       [[ 9, 10],\n",
              "        [11, 12]],\n",
              "\n",
              "       [[13, 14],\n",
              "        [15, 16]],\n",
              "\n",
              "       [[17, 18],\n",
              "        [19, 20]],\n",
              "\n",
              "       [[21, 22],\n",
              "        [23, 24]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's try 2*4*3 = 24\n",
        "A = tf.constant(A, shape = (3,8))\n",
        "A, A.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxXGqcbDHYIx",
        "outputId": "77ca350d-04de-4611-fc22-45a013970a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
              " array([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
              "        [17, 18, 19, 20, 21, 22, 23, 24]], dtype=int32)>, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Getting information from tensors\n",
        "Tensors have following attributes, the main tensor attributes are: <br>\n",
        "  * Shape\n",
        "  * Rank\n",
        "  * Axis or Dimension\n",
        "  * Size"
      ],
      "metadata": {
        "id": "uaY-BYWsH44I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a rank 4 tensor i.e. 4 dimensions\n",
        "rank4_tensor = tf.zeros([2,3,4,5]) # can also use zeros(shape = [])\n",
        "rank4_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M2SqDl5k6c1",
        "outputId": "0e3837a5-d219-43b1-f092-3cbfa3ffde25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Watch out the brackets to deduce which is which, let us see [0] element of the above tensor\n",
        "rank4_tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9hDH3cymNke",
        "outputId": "416bd0bb-1cd8-43e0-aff0-ed6615f3d18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4, 5), dtype=float32, numpy=\n",
              "array([[[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can even keep going inside to see if our deduction was correct or to access the inside elements\n",
        "rank4_tensor[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0WOJtt5mhIl",
        "outputId": "514421c2-3e67-4e1e-d0ff-98d8c7d08b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one more of such example like above\n",
        "rank4_tensor[0][0][2] # this should give the last 2nd row of zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDyTqVvvm5IV",
        "outputId": "85d7bae9-dc5b-43f5-e8a2-bebabf16284b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get all the attributes respectively\n",
        "(rank4_tensor.shape, # would be the same as give\n",
        "rank4_tensor.ndim, # would be 4 as there are 4 indices in shape(2,3,4,5) or 4 no.s to say\n",
        "tf.size(rank4_tensor)) # would be total number of elements, 2*3*4*5 = 120, 120 elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-m0XzNznlsA",
        "outputId": "283f2199-642f-44fb-a9a7-11a9609596db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing our various attributes well to just visualize better\n",
        "print(\"Datatype of each element: \", rank4_tensor.dtype)\n",
        "print(\"Shape of the tensor: \",rank4_tensor.shape)\n",
        "print(\"Number of dimensions of axis: \", rank4_tensor.ndim)\n",
        "print(\"Number of elements of 1st axis or dimension: \", rank4_tensor.shape[0]) # would be 2 as shape[0] is 2\n",
        "print(\"Number of elements of last axis or dimension: \", rank4_tensor.shape[-1]) # would be 5\n",
        "print(\"Size of the tensor: \", tf.size(rank4_tensor))\n",
        "print(\"Size which only gives number of total elements in the tensor: \", tf.size(rank4_tensor).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv-AvfSKqUqO",
        "outputId": "383930ea-9430-4a4d-d45c-d051c7588155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datatype of each element:  <dtype: 'float32'>\n",
            "Shape of the tensor:  (2, 3, 4, 5)\n",
            "Number of dimensions of axis:  4\n",
            "Number of elements of 1st axis or dimension:  2\n",
            "Number of elements of last axis or dimension:  5\n",
            "Size of the tensor:  tf.Tensor(120, shape=(), dtype=int32)\n",
            "Size which only gives number of total elements in the tensor:  120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing Tensors\n",
        "Tensors can be indexed similar to python lists"
      ],
      "metadata": {
        "id": "nVfTplWEsh2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A little exercise, let's get first 2 elements of our 1st dimension from our rank4_tensor\n",
        "print((rank4_tensor[0] # since it should in the 1st dimension out of 2\n",
        " [0] # again since it should be in the first dimension out of 3\n",
        " [0] # again since it would be in the first dimension out of 4\n",
        " [0:2])) # the first 2 of the last dimension out of 5\n",
        "\n",
        "print('\\n')\n",
        "\n",
        " # Another way\n",
        "print(\"Another way \\n\")\n",
        "rank4_tensor[0,0,0, :2] # if we leave it blank instead of 0, then it will return the whole thing 0 means getting first index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8QnrcMcsoL0",
        "outputId": "f9da9a1c-247f-43c1-f2df-5e47204b3287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
            "\n",
            "\n",
            "Another way \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets get the 1st element from each dimension from each index except for the last one\n",
        "(rank4_tensor[:1,:1,:1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLyQF46SFUMF",
        "outputId": "c463680c-e541-42f0-efa6-9182d0a4f6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a rank 2 tensor (2 dimensional)(rank = dimensions)\n",
        "rank2_tensor = tf.constant([[1,2],[2,3]])\n",
        "print(\"Shape: \", rank2_tensor.shape, \"\\nArray: \", rank2_tensor.numpy()) \n",
        "# .numpy will skip the extra info and give us only the array and dtype\n",
        "\n",
        "print(\"\\nWithout .numpy(): \", rank2_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoCdkAidKYjb",
        "outputId": "2594a583-0d2f-4bc1-e385-e649c58a93e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (2, 2) \n",
            "Array:  [[1 2]\n",
            " [2 3]]\n",
            "\n",
            "Without .numpy():  tf.Tensor(\n",
            "[[1 2]\n",
            " [2 3]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the last 2 elements of each row of our 2d tensor\n",
        "rank2_tensor[:,-1].numpy() # the first dimension of 2d tensor is row and 2nd dimension is column\n",
        "# we needed last from each row, meaning last columns\n",
        "\n",
        "# Simply we need -1 from each row, that is last element if each row, so row should be all\n",
        "# and column should be -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIjCxPr9KbK3",
        "outputId": "d4b341bc-a851-4528-d848-a416e96478e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to add extra dimension to tensors\n",
        "# Adding extra dimension to our 2d tensor for example\n",
        "rank3_tensor = rank2_tensor[..., tf.newaxis] # dots represent all before, since we add at last\n",
        "rank3_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiWmKyv9NRp7",
        "outputId": "6a1950ed-0edf-4199-f51b-f2abfbde26f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
              "array([[[1],\n",
              "        [2]],\n",
              "\n",
              "       [[2],\n",
              "        [3]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative to above tf.newaxis method\n",
        "tf.expand_dims(rank2_tensor, axis = -1) # -1 means expand the last axis\n",
        "# change the axis=-1 to 0 or 1 wherevever you want to put an extra dimension\n",
        "# it will add the extra dimension exactly where specified"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zPMzViVOIWn",
        "outputId": "e0a8f0fd-8558-47eb-aa93-d786dd140923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
              "array([[[1],\n",
              "        [2]],\n",
              "\n",
              "       [[2],\n",
              "        [3]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulation of tensors or tensor operations\n",
        "**Basic Operations** <br>\n",
        "'+' , '-' , '*' , '/' <br>\n",
        " * The rules of matrices multiplication (also called dot product) must follow i.e.<br>\n",
        " 1) The inner dimensions must match<br>\n",
        " 2) The resulting matrix will have size of outer dimensions\n"
      ],
      "metadata": {
        "id": "s_fSanqYPK3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addition operator (+)\n",
        "# add values to a tensor using '+'\n",
        "tensor = tf.constant([[1,2],[2,3]])\n",
        "print(tensor + 3) # will add 2 to all elements inside\n",
        "\n",
        "print(\"Example to get a tensor with all 3s \\n\")\n",
        "# for example to a tensor with all 3s\n",
        "tensor = tf.zeros((2,2), dtype = tf.int16) #tf.dtype is used to change type,\n",
        "# By default it was float 16 and remember (2,2) is equal to shape = (2,2)\n",
        "print(tensor + 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z6RB1NXPtVY",
        "outputId": "7f9a354a-fd71-4d65-d674-d90e8c8fd7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4 5]\n",
            " [5 6]], shape=(2, 2), dtype=int32)\n",
            "Example to get a tensor with all 3s \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [3 3]], shape=(2, 2), dtype=int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# However the original tensor would be unchanged if we not assign it see below\n",
        "tensor = tf.zeros((2,2), dtype = tf.int32)\n",
        "print(tensor) #Gives all zeros, so to change it do the following\n",
        "tensor = tensor + 3\n",
        "print(\"\\nThe changed tensor: \", tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLCSMW5LRxOt",
        "outputId": "44598706-ebaf-4d51-eeed-f8ff2f369d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 0]\n",
            " [0 0]], shape=(2, 2), dtype=int32)\n",
            "\n",
            "The changed tensor:  tf.Tensor(\n",
            "[[3 3]\n",
            " [3 3]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mulitplication, same as +\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woHbd1U-TDkx",
        "outputId": "ae7a2df5-0ee1-4339-f895-a7b847c33f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[30, 30],\n",
              "       [30, 30]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substraction -\n",
        "tensor - 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8KqiAYdTLVQ",
        "outputId": "9f04b890-0d41-4ccb-d204-1c134b4682c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[1, 1],\n",
              "       [1, 1]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also use tensorflow built in functions for the same thing too\n",
        "print(tf.multiply(tensor, 10)) # tf.math.multiply and tf.multiply are same thing\n",
        "# The original tensor will remain unchanged\n",
        "print(\"\\n\",tensor)\n",
        "# To assign it just use tensor = tf.multiply(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-zx5BRyTnB4",
        "outputId": "08ab85cf-4509-4838-c3b1-279eb9fbe5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[30 30]\n",
            " [30 30]], shape=(2, 2), dtype=int32)\n",
            "\n",
            " tf.Tensor(\n",
            "[[3 3]\n",
            " [3 3]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fully utlize gpu and better performance use tf.math.<\"whatever you want\">"
      ],
      "metadata": {
        "id": "_GZA_yCQUHM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Multiplication** <br>\n",
        "In machine learning, matrix mulitplication is one of the most common tensor operations."
      ],
      "metadata": {
        "id": "gmqgEnSqUX19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication in tensorflow\n",
        "# multiplying a tensor/matrix with itself\n",
        "print(tf.linalg.matmul(tensor, tensor)) # we can drop the middle linalg \n",
        "# for most of the tf.something1.something2 we can drop something1, it is okay\n",
        "\n",
        "print(\"\\nWithout .linalg and just tf.matmul: \", tf.matmul(tensor, tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFVTzjroVC71",
        "outputId": "01d1ecfe-60eb-44f7-e20a-fb542f9d150e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[18 18]\n",
            " [18 18]], shape=(2, 2), dtype=int32)\n",
            "\n",
            "Without .linalg and just tf.matmul:  tf.Tensor(\n",
            "[[18 18]\n",
            " [18 18]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "int16 would not work so make sure dtype of tensor is not int16"
      ],
      "metadata": {
        "id": "dKrjjD8tX5Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor * tensor would be element wise and would not yield matrix multiplication result \n",
        "\n",
        "# Little exercise\n",
        "A = tf.constant([[1, 2, 5], [7, 2, 1], [3, 3, 3]])\n",
        "B = tf.constant([[3, 5], [6, 7], [1, 8]])\n",
        "\n",
        "AB = tf.matmul(A, B) # A*B matrix multiplication\n",
        "\n",
        "print(AB.numpy()) # remember .numpy() to just get the result and no extra info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctRoixpKX97i",
        "outputId": "d98bc8ef-8967-4197-ef06-3e1f74f67ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20 59]\n",
            " [34 57]\n",
            " [30 60]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication using '@' operator in python\n",
        "A @ B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf_-B5PTdrwA",
        "outputId": "8fa14578-108a-46fc-ff23-0d1331b72820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[20, 59],\n",
              "       [34, 57],\n",
              "       [30, 60]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remainder, we can shape using tf.reshape\n",
        "tf.reshape(B, shape = (2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Tvcck5fUt5",
        "outputId": "03d947f4-8572-4de3-da29-304a1a1a0aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[3, 5, 6],\n",
              "       [7, 1, 8]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the size after reshape\n",
        "tf.reshape(B, shape = (2,3)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdFH3y14gaQc",
        "outputId": "12b47301-1ffb-443d-a59d-99ef4fdc55dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can do the same with the transpose\n",
        "tf.transpose(B), tf.reshape(B, shape = (2,3))\n",
        "# Can see the difference, reshape just arranges to make up for the given dimensions if possible\n",
        "# meaning B was 3*2 = 6, and after reshape 2*3=6 so, this is adjustable by reshape\n",
        "# Transpose changes columns to rows and rows to column (Swaps axes) just shape changes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boyeqD82gzc8",
        "outputId": "ad620402-220c-4a76-aad8-5ed4c3b4c4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[3, 6, 1],\n",
              "        [5, 7, 8]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[3, 5, 6],\n",
              "        [7, 1, 8]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dot product**<br>\n",
        "Matrix multiplication is also called as dot product.\n",
        "One can perform matrix multiplication using: <br>\n",
        " * tf.mathmul()\n",
        " * tf.tensordot()"
      ],
      "metadata": {
        "id": "-MZ9U1_miBMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets perform dot product which will require the trsnapose or reshape, this time we use transpose\n",
        "A = tf.constant([[1, 2, 5], [7, 2, 1], [3, 3, 3]])\n",
        "B = tf.constant([[3, 5, 6], [7, 1, 8]])\n",
        "print(A.shape, B.shape) # since inner elements are not same i.e. 3 for A and 2 for B\n",
        "\n",
        "# To multiply we will need same inner dimensions\n",
        "# By swaping 2 and 3 in B or transpose in other words, we can get same inner dimension of 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVV8CuAAih5f",
        "outputId": "acd16aaa-b03a-4c28-89ba-d6282bd6ef01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3) (2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication using tf.tensordot()\n",
        "print(tf.transpose(B))\n",
        "print(tf.tensordot(A, tf.transpose(B), axes = 1)) # read documentation to learn more, but axes is need to provided or it thorows error\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu1Fj9evjuFa",
        "outputId": "10dc48f8-25e2-4428-ce13-cc322479125e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[3 7]\n",
            " [5 1]\n",
            " [6 8]], shape=(3, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[43 49]\n",
            " [37 59]\n",
            " [42 48]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally you transpose to satistfy matrix multiplication rules, rather than reshape<br>\n",
        "Generally we use tf.mathmul()"
      ],
      "metadata": {
        "id": "Bg1FRRBklCMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can change tensor datatype, as we did earlier, but this time explicitely\n",
        "print(A.dtype) # will show int32 by feault\n",
        "A = tf.cast(A, dtype = tf.float16) # This tf.cast(matrix,dtype) is the way to do it\n",
        "print(A.dtype) \n",
        "\n",
        "# float16 or 16 precision in general is typically faster in calculations, need less space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePF93XtJlMlf",
        "outputId": "b13136d6-46a3-4f2f-ee4c-71e9be73a8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float16'>\n",
            "<dtype: 'float16'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregating tensors\n",
        "Aggregating tensors = condensing them from multiple values down to a smaller amount of values"
      ],
      "metadata": {
        "id": "QedcEicXn3BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To get absolute values\n",
        "# Not the best way, but should know\n",
        "A = tf.constant([-1, -3]) # A tensor\n",
        "tf.abs(A) # will turn all elements to absolute or mode |x|"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di5LWupRgoEe",
        "outputId": "e3b3e188-d7c8-41be-e410-edf7a2d07061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forms of aggregation:\n",
        " * Get minimum\n",
        " * Get maximum\n",
        " * Get mean \n",
        " * Get sum\n",
        " * Get variance\n",
        " * Get std deviation <br>\n",
        " of the tensor"
      ],
      "metadata": {
        "id": "02dp2G6chj_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a tensor and use it for all the forms\n",
        "A = tf.constant([[[1,2,3], [7,3,5]], [[9,6,13], [11,15,14]]])\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xq3mteOhr_R",
        "outputId": "7eaf0ef6-4349-46e9-bd19-6f5135d43560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
              "array([[[ 1,  2,  3],\n",
              "        [ 7,  3,  5]],\n",
              "\n",
              "       [[ 9,  6, 13],\n",
              "        [11, 15, 14]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the max across all the dimensions\n",
        "# tf.math.reduce_max(A) or:\n",
        "tf.reduce_max(A) # Both gives same results and are the same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXoD4_eMi5T0",
        "outputId": "80ed55f4-fe0b-4228-ffda-a86570d0f453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting max along an axis or dimension\n",
        "tf.reduce_max(A, axis = 1) # This should give max along the second dimension which is 2 in this case\n",
        "# As we see this gives the max row/block from 2nd dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRob0oZ3jnX0",
        "outputId": "bb36ffa9-da57-4ccf-fcc9-80e6cbffed8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 7,  3,  5],\n",
              "       [11, 15, 14]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting max from each row/block\n",
        "tf.reduce_max(A, axis = 2) # This will give from the 3rd axis which is 3, can be seen from shape()\n",
        "# The output should be 3,7,13,15 because those are the max in their respective rows\n",
        "# Axis also starts from 0 because it is indexing inside shape() of a particular tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGZw_CXekpgk",
        "outputId": "130ffb77-92d0-424e-f391-db282d01733a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 3,  7],\n",
              "       [13, 15]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same way getting minimum\n",
        "print(\"Minimum of all: \", tf.reduce_min(A)) # Axis not specified means 0th axis or all elements\n",
        "print(\"\\nMinimum of 2nd dimension that is 2 here in shape(): \", tf.reduce_min(A, axis = 1))\n",
        "print(\"\\nMinimum of the last dimension in shape() which is 2: \", tf.reduce_min(A, axis = 2))\n",
        "# The abve line will give from each row\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjWIzViklTaA",
        "outputId": "4a8d4854-ff50-4ebf-9299-30e4943ee597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum of all:  tf.Tensor(1, shape=(), dtype=int32)\n",
            "\n",
            "Minimum of 1st dimension that is 2 here in shape():  tf.Tensor(\n",
            "[[ 1  2  3]\n",
            " [ 9  6 13]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "Minimum of the last dimension in shape() which is 2:  tf.Tensor(\n",
            "[[ 1  3]\n",
            " [ 6 11]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly getting the mean\n",
        "print(\"Mean of the entire tensor: \", tf.reduce_mean(A)) # Remember nothing specified means axis = 0\n",
        "print(\"\\nMean along the 2nd dimension/axis of shape(): \", tf.reduce_mean(A, axis = 1))\n",
        "print(\"\\nMean of the last dimension: \", tf.reduce_mean(A, axis = 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIXK7tyjmZae",
        "outputId": "9987e3eb-3f35-40b3-a30e-ee3edfae6085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of the entire tensor:  tf.Tensor(7, shape=(), dtype=int32)\n",
            "\n",
            "Mean along the 2nd dimension/axis of shape():  tf.Tensor(\n",
            "[[ 4  2  4]\n",
            " [10 10 13]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "Mean of the last dimension:  tf.Tensor(\n",
            "[[ 2  5]\n",
            " [ 9 13]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarly for the sum\n",
        "print(\"Sum of the entire tensor: \", tf.reduce_sum(A))\n",
        "print(\"\\nSum along the second dimension/axis: \", tf.reduce_sum(A, axis = 1))\n",
        "print(\"\\nSum along the last dimension/axis: \", tf.reduce_sum(A, axis = 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGi5WkSiniqi",
        "outputId": "df1854c7-7cfb-4923-f6b8-88146d1c6fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of the entire tensor:  tf.Tensor(89, shape=(), dtype=int32)\n",
            "\n",
            "Sum along the second dimension/axis:  tf.Tensor(\n",
            "[[ 8  5  8]\n",
            " [20 21 27]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "Sum along the last dimension/axis:  tf.Tensor(\n",
            "[[ 6 15]\n",
            " [28 40]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If did not understand about the 2nd dimesion sums or averages, this is how it happens: <br>\n",
        "* For and sum too it is index to index of respective row, meaning:<br> \n",
        "[1,2,3],[7,3,5] -> this is our first element in 2nd dimension, now: <br>\n",
        "for the sum: 1+7=8, 2+3=5, 3+5=8, hence [8 5 8] in the sum\n",
        "* For the mean: <br>\n",
        "[1,2,3],[7,3,5] -> this is our first element in 2nd dimension, now: <br>\n",
        "1+7/2=4, 2+3/2=2, 3+5/2=4, hence [4 2 4] in the mean\n",
        "<br>\n",
        "<br>\n",
        "Hence, 1 with 7, 2 with 3, and 3 with 5 since they same index in corresponding row"
      ],
      "metadata": {
        "id": "fl5E3g8DoevZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to create random tensor, but this time with numbers and no probability distribution\n",
        "random = tf.constant(np.random.randint(0, 100, size = 50)) # Creates a tensor with 50 elements between 0 and 100\n",
        "random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flwHoEyBpy7D",
        "outputId": "0d81f8f5-dd8f-4e0b-fdb4-6e101ac769a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([30, 53, 84, 26, 77, 65, 25, 62, 53,  1, 11, 40, 41, 11, 49, 78, 82,\n",
              "       16,  7, 88, 33, 17,  9, 48, 28, 16, 18, 82, 78, 76, 48, 57, 16,  7,\n",
              "       43, 28, 86, 78, 70, 36, 45, 76, 77, 35, 83, 30, 12, 87, 88, 92])>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets apply all the aggrigator forms to this tensor\n",
        "# The shape is 50 0 as we can see, since 50 elements in 1 row or 1 pair of brackets [ ]\n",
        "print(\"The maximum in the random tensor: \", tf.reduce_max(random).numpy())\n",
        "print(\"\\nThe minimum in the random tensor: \", tf.reduce_min(random).numpy())\n",
        "print(\"\\nThe mean of the random tensor: \", tf.reduce_mean(random).numpy())\n",
        "print(\"\\nThe sum of the random tensor: \", tf.reduce_sum(random).numpy()) # .numpy() to see clear/only numbers\n",
        "# We do not use axis argument because there is only 1 axis, can verify by using .shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K84qLZ2tqcqq",
        "outputId": "dfbfab9d-12f8-4fa5-bbe4-88168e05c3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum in the random tensor:  92\n",
            "\n",
            "The minimum in the random tensor:  1\n",
            "\n",
            "The mean of the random tensor:  47\n",
            "\n",
            "The sum of the random tensor:  2398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the remaining 2, i.e. variance and std deviation\n",
        "# The syntax is the same, lets find them both for the both random and A\n",
        "\n",
        "# We need to cast to float to get them, it would not work with int32\n",
        "A = tf.cast(A, dtype = tf.float16)\n",
        "print(\"Variance of A tensor along all the dimensions/axis\", tf.math.reduce_variance(A).numpy())\n",
        "print(\"\\nStd deviation of A along all the dimensions/axis\", tf.math.reduce_std(A).numpy())\n",
        "print(\"\\nVariance of A tensor along the 2nd dimensions/axis\", tf.math.reduce_variance(A, axis = 1).numpy())\n",
        "print(\"\\nStd deviation of A along all the dimensions/axis\", tf.math.reduce_std(A, axis = 1).numpy())\n",
        "\n",
        "random = tf.cast(random, dtype = tf.float16)\n",
        "print(\"\\nVariance of random tensor along all the dimensions/axis\", tf.math.reduce_variance(random).numpy())\n",
        "print(\"Std deviation of random along all the dimensions/axis\", tf.math.reduce_std(random).numpy())\n",
        "#Note that random tensor only has 1 dimension\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzXn4GvesQH6",
        "outputId": "0aa30024-478f-4869-d849-a0ae13015345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of A tensor along all the dimensions/axis 22.08\n",
            "\n",
            "Std deviation of A along all the dimensions/axis 4.7\n",
            "\n",
            "Variance of A tensor along the 2nd dimensions/axis [[ 9.    0.25  1.  ]\n",
            " [ 1.   20.25  0.25]]\n",
            "\n",
            "Std deviation of A along all the dimensions/axis [[3.  0.5 1. ]\n",
            " [1.  4.5 0.5]]\n",
            "\n",
            "Variance of random tensor along all the dimensions/axis 784.0\n",
            "Std deviation of random along all the dimensions/axis 28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”‘**Key take away from above variance and std. deviation** <br>\n",
        " * tf.math.reduce_variance() -> variance\n",
        " * tf.math.reduce_std() -> std. deviation\n",
        " * Variance and std. deviation only works with real or complex numbers meaning no int. Cast it to dytpe float as I did above, if it is int <br>\n",
        " **Note: ** The newer verison of tensor flow throws error for tf.reduce_variance without .math in between, and same for the std. deviation <br> If something like this happens with other build ins, just use the middle like .math in this case, refer the tensorflow documentation"
      ],
      "metadata": {
        "id": "rEQRhTNLu7FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To counter above problems where it does not work with ints\n",
        "# We need to import tensorflow_probability\n",
        "import tensorflow_probability as tfp #tfp is the norm\n",
        "print(tfp.stats.variance(A))\n",
        "print(\"\\n\")\n",
        "print(tfp.stats.variance(tf.cast(random, dtype = tf.int32)).numpy()) # 784, same as with float16 we found using tf.math.reduce_variance()\n",
        "\n",
        "# Lets now convert to int again and see\n",
        "print(\"After making it int: \" , tfp.stats.variance(tf.cast(A, dtype = tf.int32)))\n",
        "# Lets cast our A tensor back to int and try"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBxMKcS-1GZi",
        "outputId": "65674a0a-9ee8-4d59-d6e6-e6856814acab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[16.    4.   25.  ]\n",
            " [ 4.   36.   20.25]], shape=(2, 3), dtype=float16)\n",
            "\n",
            "\n",
            "784\n",
            "After making it int:  tf.Tensor(\n",
            "[[16  4 25]\n",
            " [ 4 36 20]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "float32 normally should be used, it is a std types for the tensors"
      ],
      "metadata": {
        "id": "Ff-wC6FF2cxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Maximum and minimum index and value"
      ],
      "metadata": {
        "id": "yEf4_lFI4MIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a random tensor using uniform distribution\n",
        "tf.random.set_seed(42) # Global seed\n",
        "random = tf.random.uniform(shape=[50]) # creats 50 element random tensor from uniform distribution\n",
        "random\n",
        "# With random.unfiorm or .normal or any distribution, inside ( ) is the shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1JyXwqv4SEb",
        "outputId": "688768a4-72cc-401b-c9de-71a12bcf30e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the index/dimensional position where maximum number resides\n",
        "print(tf.argmax(random)) # argmax(tensor) gives index of the max value\n",
        "print(\"To see more clearly: \", tf.argmax(random).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SDQAXE15Ed4",
        "outputId": "f5a29b1e-43af-44ef-8101-05fb51c7463c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(42, shape=(), dtype=int64)\n",
            "To see more clearly:  42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the value\n",
        "# Just simple indexing as we have seen above\n",
        "random[tf.argmax(random)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O-nNNGn5xGH",
        "outputId": "78677f61-8163-42ce-f096-523768dba05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The discussed above method tf.reduce_max() also works the same, and is easy\n",
        "tf.reduce_max(random) # Answer is the same as above, thus, both works"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJqGb23A6FYe",
        "outputId": "1d948913-1ac1-47ef-902a-489e4a9e820e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the minimum\n",
        "print(random[tf.argmin(random)].numpy())\n",
        "print(tf.reduce_min(random).numpy())\n",
        "print((random[tf.argmin(random)] == tf.reduce_min(random)).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rwxts516ndR",
        "outputId": "a3d9ee81-9bbe-498f-fe1e-e6238e5e3c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.009463668\n",
            "0.009463668\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Squeezing a tensor (removing all single dimensions/axis)"
      ],
      "metadata": {
        "id": "9_SdkwKz7HtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a random tensor with multilple single axis in shape()\n",
        "tf.random.set_seed(42)\n",
        "random = tf.random.uniform(shape = [1,1,50]) # tf.constant( tf.random.uniform(shape = [50], shape = (1,1,50)) will give same result\n",
        "random\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVwlU1Jk7u_q",
        "outputId": "2f996f01-9aba-4a93-e441-0d79d40f6a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 50), dtype=float32, numpy=\n",
              "array([[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "         0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "         0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "         0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "         0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "         0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "         0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "         0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "         0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "         0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets squeeze and remove extra 1 dimensions to just extract the essence\n",
        "tf.squeeze(random)\n",
        "# you can also assign this squeezed to a new tensor, but I do not feel the need to use more space\n",
        "# if the original is important as well, then might consider assignimg to new tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ySZOhad8Zes",
        "outputId": "9024c491-06c2-4d15-e241-469511662d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
              "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
              "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
              "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
              "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
              "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
              "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
              "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
              "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
              "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-hot encoding tensors\n",
        "* It is a type of a Numerical encoding <br>\n",
        "* Input -> Numerical encoding (A way to represent data in numbers) <br>\n",
        "ðŸ“‘ machinelearningmastery  -> a great website for machine learning"
      ],
      "metadata": {
        "id": "Rp6OYmbP9FTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of indices\n",
        "indices = [0, 1, 2]  # These numbers can represent anything red, blue, green for example\n",
        "# Remember the list should only have numbers, what it represents is arbitrary\n",
        "\n",
        "# One hot encode our indices named list\n",
        "tf.one_hot(indices, depth = 3) # depth is just the dimension that our tensor would get\n",
        "# depth is just the number of elements in our list, according to which our tensor dimension is decided\n",
        "# 3*3 in this case"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqxrvSfq-R9R",
        "outputId": "05fff16c-a43f-406b-eb00-846030ff2995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âš“**Note:** see how it puts 1s at positions provided in the list indices, if you change numbers lets say [1,2,0] in indices list then, the 1s in the encoding will appear as: <br>\n",
        "0 1 0<br>\n",
        "0 0 1<br>\n",
        "1 0 0<br>"
      ],
      "metadata": {
        "id": "KthYwMIJAFc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of 1s and 0s we can give it custom representation for example\n",
        "tf.one_hot(indices, depth = 3, on_value = \"yes\", off_value = \"no\")\n",
        "# We will rarely use it, using 1s and 0s is the norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43O0U0hrA8Rp",
        "outputId": "9ace63ee-5d88-436c-9646-32edbe3cec14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=string, numpy=\n",
              "array([[b'yes', b'no', b'no'],\n",
              "       [b'no', b'yes', b'no'],\n",
              "       [b'no', b'no', b'yes']], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few more useful .math operations\n",
        "* square\n",
        "* log\n",
        "* square root"
      ],
      "metadata": {
        "id": "8cRpFl9rB6dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A way to create tensor of conitunes numbers\n",
        "A = tf.range(1,10) # creates a tensor of 1 to 10 numbers (notice it just has one dimension/axis)\n",
        "A.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0kXEAQCJBN",
        "outputId": "7c958744-3b09-4676-f09d-b7372986d6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To sqaure it\n",
        "tf.square(A).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otpPZv8ZCfW7",
        "outputId": "9bc653fa-2e4b-43e2-f13e-1b4c752c7ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  4,  9, 16, 25, 36, 49, 64, 81], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For sqaure root\n",
        "tf.math.sqrt(tf.cast(A, dtype = tf.float32)).numpy() # non int dtype required\n",
        "# also .math is required. Note how .math is required if a method is dtype specific"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8qe8BgkCuYe",
        "outputId": "b5bfcd71-876d-41e4-ea49-d7612f89cf00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99999994, 1.4142134 , 1.7320508 , 1.9999999 , 2.236068  ,\n",
              "       2.4494896 , 2.6457512 , 2.8284268 , 3.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To find log\n",
        "tf.math.log(tf.cast(A, dtype = tf.float32)).numpy() # Log is also dtype specific\n",
        "# int not allowed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7znMFw_6DNaH",
        "outputId": "bb4f05cc-2d34-453f-fbb8-5985718df2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
              "       1.9459102, 2.0794415, 2.1972246], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Tensors and Numpy\n",
        "* TensorFlow interacts beautifully with NumPy arrays. <br>\n",
        "* TensorFlow is build upon the tensors and NumPy is build upon the arrays. <br>\n",
        "* Numpy is fundamental python library for computing"
      ],
      "metadata": {
        "id": "1FNFlfTZDl5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor directly from a NumPy array\n",
        "A = tf.constant(np.array([1, 2, 3]))\n",
        "A "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUTmjvOEEEWJ",
        "outputId": "7ef8346d-6bd7-49ae-f7cc-f5a98359a20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn back the tensor to a NumPy array\n",
        "(np.array(A), # will convert it to a numpy array back again\n",
        " type(np.array(A))) # This will confirm it, not we did not assigned the change to A,\n",
        "#so we have to use (np.array(A)) in the bracket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnJqkBBeEZNd",
        "outputId": "31a78f90-540c-48d5-a784-c38714c1f23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3]), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way\n",
        "A.numpy(), type(A.numpy())\n",
        "# We have seen .numpy() a lot to just display clear array elements to see\n",
        "# However, if we assign it by for example A = A.numpy(), then it will change the tensor to numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzxTUmAuFGS8",
        "outputId": "4bcce851-6dd2-4314-8b30-5b03bf906122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3]), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is useful if some functionality does not work with tensor type but works with numpy\n",
        "# here is a way to access a particular element in tensor using numpy to only get the number\n",
        "A.numpy()[1] # should show 2 as at index 1 value is 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x-GNkViFuvW",
        "outputId": "5d60387a-f156-499f-a3f6-f2400e71e4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default types for each are different\n",
        "A = tf.constant(np.array([1, 2, 3]))\n",
        "B = tf.constant([1, 2, 3])\n",
        "\n",
        "#Check the data type\n",
        "A.dtype, B.dtype # A would be with 64 precison while B with 32 by default \n",
        "\n",
        "# Thus, converting from numpy array would have 64 precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QtmnuZ0GI-j",
        "outputId": "7d46c950-8bae-4baf-a07b-84b4de0b1ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tf.int64, tf.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. @tf.function\n",
        "The tf.function API is used in TF2.0 to create graphs for eagerly executed code.\n",
        "\n",
        "There are two ways you can use this.\n",
        "1. As a decorator: Using @tf.function decorator before your code will create a graph for that piece of code.\n",
        "\n",
        "2. As a callable function : In this method you can simply tf.function-ise an existing function to create a graph for that function."
      ],
      "metadata": {
        "id": "pwAEeam7S_Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Finding access to GPUs"
      ],
      "metadata": {
        "id": "Kxf1sGAGPpYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see the physical devices the run identifies/uses using run timr\n",
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Wf8IgOP819",
        "outputId": "65cfb5fa-c55d-413c-9117-067450ce6c3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can specific by using\n",
        "tf.config.list_physical_devices(\"GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4x9YjK7QWL-",
        "outputId": "5fca4688-57dd-4a1d-a3e1-c2701bca03df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google colab provides free to use GPU or TPU, by default it would be just CPU\n",
        "# TPU requires set up, so lets only focus on gpu for now\n",
        "# Go to rumtime -> change runtime type, and choose GPU\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as8tQTmYQgbb",
        "outputId": "484b6b42-42f5-4102-c196-b8f2b7dc3fe2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alright, we have a cpu and a gpu\n",
        "!nvidia-smi # This will show what type of gpu you are using"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAKFZ-gbRYTC",
        "outputId": "11392f84-0b34-45ef-d863-f1d8133e7f6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 15 12:11:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”‘**Note:** If you have access to a CUDA-enabled GPU, TensorFlow will automatically use it when possible. We can see above it is a CUDA powered GPU, CUDA version: 11.2 (by the time I am writing this notebook)"
      ],
      "metadata": {
        "id": "e_pEytlLRvh0"
      }
    }
  ]
}